name: scheduled-scrape

on:
  schedule:
    - cron: '0 3,11,19 * * *'   # Ejecuta 3 veces al día (Bogotá)
  workflow_dispatch:             # Permite ejecutarlo manualmente

jobs:
  run-scraper:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          playwright install chromium

      - name: Run scraper
        run: |
          mkdir -p artifacts
          python scraper/scraper_playwright.py > artifacts/results.json
        continue-on-error: true

      - name: Save data to DB
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: |
          python scraper/save_to_db.py artifacts/results.json
        continue-on-error: true

      - name: Upload scrape results
        uses: actions/upload-artifact@v4
        with:
          name: results
          path: artifacts/results.json
